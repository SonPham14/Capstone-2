import joblib
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier
from sklearn.svm import SVC
from sklearn.metrics import classification_report, accuracy_score

# ƒê·ªçc d·ªØ li·ªáu t·ª´ file CSV
df = pd.read_csv("dataset.csv")

# Ch·ªâ thay th·∫ø NaN trong c√°c c·ªôt ki·ªÉu chu·ªói (c√°ch m·ªõi, ƒë√∫ng chu·∫©n Pandas 3.0)
df.fillna({col: '' for col in df.select_dtypes(include=['object']).columns}, inplace=True)

# Ki·ªÉm tra ki·ªÉu d·ªØ li·ªáu c·ªßa t·ª´ng c·ªôt
print(df.dtypes)

# # X·ª≠ l√Ω c·ªôt label ƒë·ªÉ ƒë·∫£m b·∫£o n√≥ ch·ª©a gi√° tr·ªã h·ª£p l·ªá
# if df['label'].dtype == 'float64':  # N·∫øu l√† s·ªë th·ª±c, chuy·ªÉn th√†nh s·ªë nguy√™n
#     df['label'] = df['label'].fillna(0).astype(int)
# else:  # N·∫øu l√† chu·ªói, thay th·∫ø NaN b·∫±ng "unknown"
#     df['label'] = df['label'].fillna('unknown').astype(str)

# Ki·ªÉm tra gi√° tr·ªã trong c·ªôt label
print(df['label'].unique())

# Ch·ªçn c·ªôt feature (lo·∫°i b·ªè c√°c c·ªôt kh√¥ng mong mu·ªën n·∫øu c√≥)
cols_to_drop = ['srcip', 'dstip']
X = df.drop(columns=[col for col in cols_to_drop if col in df.columns])

# Ch·ªçn c·ªôt label l√†m target
y = df["label"]

# Ki·ªÉm tra l·∫°i X tr∆∞·ªõc khi vector h√≥a
print("Columns in X:", X.columns)

# Chuy·ªÉn to√†n b·ªô d·ªØ li·ªáu th√†nh chu·ªói v√† gh√©p c√°c c·ªôt th√†nh m·ªôt chu·ªói duy nh·∫•t
X = X.astype(str).agg(' '.join, axis=1)

# Chuy·ªÉn d·ªØ li·ªáu vƒÉn b·∫£n th√†nh d·∫°ng vector TF-IDF
vectorizer = TfidfVectorizer()
X_vec = vectorizer.fit_transform(X)

# Chia d·ªØ li·ªáu th√†nh t·∫≠p hu·∫•n luy·ªán v√† t·∫≠p ki·ªÉm tra (80%/20%)
X_train, X_test, y_train, y_test = train_test_split(X_vec, y, test_size=0.2, random_state=42)

# üîπ 1Ô∏è‚É£ M√¥ h√¨nh Random Forest
rf_model = RandomForestClassifier()
rf_model.fit(X_train, y_train)
y_pred_rf = rf_model.predict(X_test)
print("\nüîπ Random Forest Results:")
print("Accuracy:", accuracy_score(y_test, y_pred_rf))
print(classification_report(y_test, y_pred_rf))

# üîπ 2Ô∏è‚É£ M√¥ h√¨nh XGBoost
xgb_model = XGBClassifier(eval_metric='mlogloss')
xgb_model.fit(X_train, y_train)
y_pred_xgb = xgb_model.predict(X_test)
print("\nüîπ XGBoost Results:")
print("Accuracy:", accuracy_score(y_test, y_pred_xgb))
print(classification_report(y_test, y_pred_xgb))

# üîπ 3Ô∏è‚É£ M√¥ h√¨nh SVM
# svm_model = SVC(kernel='linear', probability=True)
# svm_model.fit(X_train, y_train)
# y_pred_svm = svm_model.predict(X_test)
# print("\nüîπ SVM Results:")
# print("Accuracy:", accuracy_score(y_test, y_pred_svm))
# print(classification_report(y_test, y_pred_svm))

# # Save the model to disk
# joblib.dump(model, 'wazuh_classifier.joblib')
# print("Model saved to wazuh_classifier.joblib")

# # Save the vectorizer to disk
# joblib.dump(vectorizer, "tfidf_vectorizer.joblib")
# print("Vectorizer saved to tfidf_vectorizer.joblib")

# L∆∞u m√¥ h√¨nh t·ªët nh·∫•t
# joblib.dump(rf_model, 'random_forest_model.joblib')
# joblib.dump(xgb_model, 'xgboost_model.joblib')
# # joblib.dump(svm_model, 'svm_model.joblib')
# joblib.dump(vectorizer, "tfidf_vectorizer.joblib")